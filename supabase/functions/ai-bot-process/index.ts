import { serve } from "https://deno.land/std@0.190.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const SUPABASE_URL = Deno.env.get("SUPABASE_URL") ?? "";
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";
const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY") ?? "";
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY") ?? "";
const EVOLUTION_API_URL = Deno.env.get("EVOLUTION_API_URL") ?? "";
const EVOLUTION_API_KEY = Deno.env.get("EVOLUTION_API_KEY") ?? "";

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);

// ============================================================================
// INTERFACES
// ============================================================================

interface InitialQuestion {
  questionId: string;
  questionText: string;
  questionType: string;
  position: number;
}

interface AIBot {
  id: string;
  organization_id: string;
  name: string;
  system_prompt: string;
  welcome_message: string | null;
  transfer_message: string | null;
  out_of_hours_message: string | null;
  transfer_keywords: string[] | null;
  max_messages_before_transfer: number | null;
  transfer_on_confusion: boolean | null;
  working_hours_start: string | null;
  working_hours_end: string | null;
  working_days: number[] | null;
  max_energy_per_message: number | null;
  max_energy_per_conversation: number | null;
  initial_qualification_enabled: boolean | null;
  initial_questions: InitialQuestion[] | null;
  // Campos de personalidade e identidade
  gender: string | null;
  age_range: string | null;
  brazilian_state: string | null;
  personality_description: string | null;
  company_differential: string | null;
  regional_expressions: string[] | null;
  response_length: string | null;
  service_type: string | null;
  product_scope: 'all' | 'selected' | 'none';
  use_rag_search: boolean;
  // AI Model for chat
  ai_model_chat: string | null;
  // Voice settings
  voice_enabled: boolean | null;
  voice_id: string | null;
  voice_name: string | null;
  audio_response_probability: number | null;
  voice_style: string | null;
}

interface BotProduct {
  id: string;
  name: string;
  description: string | null;
  sales_script: string | null;
  price_1_unit: number | null;
  price_3_units: number | null;
  price_6_units: number | null;
  price_12_units: number | null;
  hot_site_url: string | null;
  usage_period_days: number | null;
  // Enhanced with FAQs, ingredients, and kit sales hacks
  faqs?: Array<{question: string, answer: string}>;
  ingredients?: Array<{name: string, description: string | null}>;
  kits?: Array<{quantity: number, price_cents: number, sales_hack: string | null, usage_period_days: number | null}>;
}

interface ConversationContext {
  conversationId: string;
  instanceId: string;
  organizationId: string;
  contactName: string;
  phoneNumber: string;
  chatId: string;
  botMessagesCount: number;
  botEnergyConsumed: number;
  leadId: string | null;
  qualificationStep: number;
  qualificationCompleted: boolean;
}

interface ProcessResult {
  success: boolean;
  action: 'responded' | 'transferred' | 'no_energy' | 'out_of_hours' | 'error' | 'qualification';
  message?: string;
  energyUsed?: number;
}

// ============================================================================
// HELPERS
// ============================================================================

function isWithinWorkingHours(bot: AIBot): boolean {
  if (!bot.working_hours_start || !bot.working_hours_end || !bot.working_days) {
    return true; // Sem restriÃ§Ã£o = sempre disponÃ­vel
  }

  const now = new Date();
  // Ajustar para horÃ¡rio de BrasÃ­lia (UTC-3)
  const brasiliaOffset = -3 * 60;
  const localTime = new Date(now.getTime() + (brasiliaOffset - now.getTimezoneOffset()) * 60000);
  
  const dayOfWeek = localTime.getDay();
  const currentHour = localTime.getHours();
  const currentMinute = localTime.getMinutes();
  const currentTimeMinutes = currentHour * 60 + currentMinute;

  // Verificar dia da semana
  if (!bot.working_days.includes(dayOfWeek)) {
    return false;
  }

  // Verificar horÃ¡rio
  const [startHour, startMin] = bot.working_hours_start.split(':').map(Number);
  const [endHour, endMin] = bot.working_hours_end.split(':').map(Number);
  const startMinutes = startHour * 60 + startMin;
  const endMinutes = endHour * 60 + endMin;

  return currentTimeMinutes >= startMinutes && currentTimeMinutes <= endMinutes;
}

function shouldTransferByKeywords(message: string, keywords: string[] | null): boolean {
  if (!keywords || keywords.length === 0) return false;
  
  const lowerMessage = message.toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g, '');
  
  return keywords.some(keyword => {
    const lowerKeyword = keyword.toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g, '');
    return lowerMessage.includes(lowerKeyword);
  });
}

// ============================================================================
// AUDIO TRANSCRIPTION
// ============================================================================

async function transcribeAudio(mediaUrl: string): Promise<{ text: string; tokensUsed: number }> {
  console.log('ğŸ¤ Transcribing audio from:', mediaUrl);
  
  try {
    // Download audio from Supabase storage
    const audioResponse = await fetch(mediaUrl);
    if (!audioResponse.ok) {
      throw new Error(`Failed to download audio: ${audioResponse.status}`);
    }
    
    const audioBlob = await audioResponse.blob();
    const audioBuffer = await audioBlob.arrayBuffer();
    
    // Create form data for OpenAI Whisper
    const formData = new FormData();
    formData.append('file', new Blob([audioBuffer], { type: 'audio/ogg' }), 'audio.ogg');
    formData.append('model', 'whisper-1');
    formData.append('language', 'pt');
    formData.append('response_format', 'json');
    
    const whisperResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
      },
      body: formData,
    });
    
    if (!whisperResponse.ok) {
      const errorText = await whisperResponse.text();
      console.error('âŒ Whisper error:', whisperResponse.status, errorText);
      throw new Error(`Whisper error: ${whisperResponse.status}`);
    }
    
    const result = await whisperResponse.json();
    const transcribedText = result.text || '';
    
    console.log('âœ… Audio transcribed:', transcribedText.substring(0, 100) + '...');
    
    // Estimativa de tokens: ~100 tokens para transcriÃ§Ã£o
    return { text: transcribedText, tokensUsed: 100 };
  } catch (error) {
    console.error('âŒ Audio transcription error:', error);
    throw error;
  }
}

// ============================================================================
// IMAGE ANALYSIS
// ============================================================================

// Prompt especializado para receitas mÃ©dicas em fotos
const IMAGE_MEDICAL_TURBO_PROMPT = `VocÃª Ã© um especialista farmacÃªutico com mais de 20 anos de experiÃªncia em interpretar receitas mÃ©dicas fotografadas.

TAREFA CRÃTICA: Analisar esta FOTO de receita mÃ©dica e extrair informaÃ§Ãµes com mÃ¡xima precisÃ£o.

HABILIDADES ESPECIAIS:
- Interpretar caligrafia mÃ©dica difÃ­cil e ilegÃ­vel em fotos
- Reconhecer abreviaÃ§Ãµes farmacÃªuticas e mÃ©dicas
- Identificar medicamentos manipulados e industrializados
- Extrair dosagens mesmo com escrita irregular

EXTRAIA E ORGANIZE:

ğŸ“‹ MEDICAMENTOS/FÃ“RMULAS:
Para cada item encontrado, extraia:
- Nome do medicamento ou fÃ³rmula
- Componentes ativos (se manipulado)
- ConcentraÃ§Ã£o/dosagem (mg, mcg, UI, %)
- Forma farmacÃªutica (cÃ¡psula, comprimido, creme, etc.)
- Quantidade prescrita (ex: 60 cÃ¡psulas)

ğŸ’Š POSOLOGIA:
- FrequÃªncia de uso (1x ao dia, 2x ao dia, etc.)
- HorÃ¡rios especÃ­ficos (se mencionados)
- DuraÃ§Ã£o do tratamento (se indicada)
- InstruÃ§Ãµes especiais (em jejum, com alimentos, etc.)

ğŸ‘¨â€âš•ï¸ PRESCRITOR:
- Nome do mÃ©dico/profissional
- CRM/registro profissional (se visÃ­vel)
- Especialidade (se identificÃ¡vel)

âš ï¸ OBSERVAÃ‡Ã•ES:
- Qualquer informaÃ§Ã£o adicional relevante
- Alertas sobre interaÃ§Ãµes ou cuidados
- Partes ilegÃ­veis ou duvidosas

REGRAS:
1. Se algo estiver ilegÃ­vel, indique "[ilegÃ­vel]" e tente uma interpretaÃ§Ã£o provÃ¡vel
2. Use formato estruturado e fÃ¡cil de ler
3. Priorize precisÃ£o em dosagens e quantidades
4. Seja direto e objetivo na resposta`;

async function analyzeImage(
  mediaUrl: string, 
  userMessage: string, 
  botSystemPrompt: string,
  useMedicalMode: boolean = false,
  modelToUse: string = 'google/gemini-2.5-flash'
): Promise<{ text: string; tokensUsed: number; modelUsed: string }> {
  console.log('ğŸ–¼ï¸ Analyzing image from:', mediaUrl, 'Medical mode:', useMedicalMode, 'Model:', modelToUse);
  
  try {
    // Escolher prompt baseado no modo
    const systemPrompt = useMedicalMode 
      ? IMAGE_MEDICAL_TURBO_PROMPT 
      : `${botSystemPrompt}\n\nO cliente enviou uma imagem. Analise-a e responda de forma Ãºtil.`;

    // For medical mode, use Pro model for better accuracy if no specific model configured
    const effectiveModel = useMedicalMode && modelToUse === 'google/gemini-2.5-flash' 
      ? 'google/gemini-2.5-pro' 
      : modelToUse;

    // Usar modelo configurado via Lovable AI para anÃ¡lise de imagem
    const response = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LOVABLE_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: effectiveModel,
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: [
              {
                type: 'image_url',
                image_url: { url: mediaUrl }
              },
              {
                type: 'text',
                text: useMedicalMode 
                  ? 'Por favor, analise esta foto de receita mÃ©dica e extraia todas as informaÃ§Ãµes relevantes.'
                  : (userMessage || 'O que vocÃª vÃª nesta imagem?')
              }
            ]
          }
        ],
        max_tokens: useMedicalMode ? 1500 : 500,
        temperature: useMedicalMode ? 0.3 : 0.7,
      }),
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ Image analysis error:', response.status, errorText);
      throw new Error(`Image analysis error: ${response.status}`);
    }
    
    const data = await response.json();
    const analysisText = data.choices?.[0]?.message?.content || '';
    const tokensUsed = (data.usage?.prompt_tokens || 0) + (data.usage?.completion_tokens || 0);
    
    console.log('âœ… Image analyzed with', effectiveModel, ':', analysisText.substring(0, 100) + '...');
    
    return { text: analysisText, tokensUsed, modelUsed: effectiveModel };
  } catch (error) {
    console.error('âŒ Image analysis error:', error);
    throw error;
  }
}

// ============================================================================
// BOT PRODUCTS & KNOWLEDGE
// ============================================================================

async function getBotProducts(botId: string, organizationId: string, productScope: 'all' | 'selected' | 'none'): Promise<BotProduct[]> {
  // If scope is 'none', don't fetch products
  if (productScope === 'none') {
    console.log('ğŸ“¦ Product scope is none, skipping product fetch');
    return [];
  }

  let productIds: string[] = [];
  
  // If scope is 'selected', get only the products linked to this bot
  if (productScope === 'selected') {
    const { data: botProducts } = await supabase
      .from('ai_bot_products')
      .select('product_id')
      .eq('bot_id', botId);
    
    if (!botProducts || botProducts.length === 0) {
      console.log('ğŸ“¦ No products selected for bot');
      return [];
    }
    productIds = botProducts.map((bp: any) => bp.product_id);
  }

  // Build query for products
  let query = supabase
    .from('lead_products')
    .select(`
      id,
      name,
      description,
      sales_script,
      price_1_unit,
      price_3_units,
      price_6_units,
      price_12_units,
      hot_site_url,
      usage_period_days
    `)
    .eq('organization_id', organizationId)
    .eq('is_active', true);

  // Filter by selected products if scope is 'selected'
  if (productScope === 'selected' && productIds.length > 0) {
    query = query.in('id', productIds);
  }

  const { data: products, error } = await query;

  if (error || !products || products.length === 0) {
    console.log('ğŸ“¦ No products found');
    return [];
  }

  // Enhance products with FAQs, ingredients, and kits
  const enhancedProducts: BotProduct[] = [];

  for (const product of products) {
    // Get FAQs for this product
    const { data: faqs } = await supabase
      .from('product_faqs')
      .select('question, answer')
      .eq('product_id', product.id)
      .eq('is_active', true)
      .order('position');

    // Get ingredients/composition for this product
    const { data: ingredients } = await supabase
      .from('product_ingredients')
      .select('name, description')
      .eq('product_id', product.id)
      .order('position');

    // Get kits with prices and sales hacks
    const { data: kits } = await supabase
      .from('product_price_kits')
      .select('quantity, price_cents, sales_hack, usage_period_days')
      .eq('product_id', product.id)
      .eq('is_active', true)
      .order('quantity');

    enhancedProducts.push({
      ...product,
      faqs: faqs || [],
      ingredients: ingredients || [],
      kits: kits || [],
    });
  }

  console.log(`ğŸ“¦ Loaded ${enhancedProducts.length} products with FAQs, ingredients, and kits`);
  return enhancedProducts;
}

async function getBotKnowledge(botId: string): Promise<Array<{question: string, answer: string}>> {
  const { data, error } = await supabase
    .from('ai_bot_knowledge')
    .select('question, answer')
    .eq('bot_id', botId)
    .eq('is_active', true)
    .eq('knowledge_type', 'faq')
    .order('priority', { ascending: true });

  if (error || !data) return [];
  return data.filter(k => k.question && k.answer);
}

// ============================================================================
// SEMANTIC SEARCH (RAG)
// ============================================================================

async function generateQueryEmbedding(text: string): Promise<number[] | null> {
  const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY") ?? "";
  
  try {
    const response = await fetch('https://ai.gateway.lovable.dev/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LOVABLE_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'text-embedding-3-small',
        input: text.substring(0, 2000),
      }),
    });

    if (!response.ok) {
      console.error('Embedding API error:', response.status);
      return null;
    }

    const data = await response.json();
    return data.data[0].embedding;
  } catch (err) {
    console.error('Error generating query embedding:', err);
    return null;
  }
}

interface SemanticSearchResult {
  content_text: string;
  content_type: string;
  product_id: string;
  similarity: number;
  metadata: Record<string, any>;
}

async function semanticSearch(
  query: string, 
  organizationId: string, 
  productIds: string[] | null,
  limit: number = 5
): Promise<SemanticSearchResult[]> {
  console.log('ğŸ” Starting semantic search for:', query.substring(0, 50) + '...');
  
  const embedding = await generateQueryEmbedding(query);
  if (!embedding) {
    console.log('âš ï¸ Could not generate embedding, skipping semantic search');
    return [];
  }

  // Use pgvector cosine similarity search
  // We need to use a raw RPC call since the supabase client doesn't support vector operations directly
  const { data, error } = await supabase.rpc('match_product_embeddings', {
    query_embedding: embedding,
    match_threshold: 0.7,
    match_count: limit,
    filter_organization_id: organizationId,
    filter_product_ids: productIds,
  });

  if (error) {
    console.error('Semantic search error:', error);
    return [];
  }

  console.log(`ğŸ” Found ${data?.length || 0} semantic matches`);
  return data || [];
}

// ============================================================================
// LEAD MEMORY CONTEXT
// ============================================================================

interface LeadMemoryContext {
  lead_name: string | null;
  lead_notes: string | null;
  lead_stars: number | null;
  preferences: Array<{
    preference_type: string;
    preference_value: string;
    confidence_score: number;
  }>;
  last_summary: {
    summary_text: string;
    key_topics: string[];
    next_steps: string | null;
    created_at: string;
  } | null;
}

async function getLeadMemoryContext(organizationId: string, leadId: string | null): Promise<LeadMemoryContext | null> {
  if (!leadId) return null;

  try {
    // Buscar preferÃªncias
    const { data: preferences } = await supabase
      .from('lead_ai_preferences')
      .select('preference_type, preference_value, confidence_score')
      .eq('lead_id', leadId)
      .order('confidence_score', { ascending: false })
      .limit(10);

    // Buscar Ãºltimo resumo
    const { data: summaries } = await supabase
      .from('lead_conversation_summaries')
      .select('summary_text, key_topics, next_steps, created_at')
      .eq('lead_id', leadId)
      .order('created_at', { ascending: false })
      .limit(1);

    // Buscar dados do lead
    const { data: lead } = await supabase
      .from('leads')
      .select('name, notes, stars')
      .eq('id', leadId)
      .single();

    return {
      lead_name: lead?.name || null,
      lead_notes: lead?.notes || null,
      lead_stars: lead?.stars || null,
      preferences: preferences || [],
      last_summary: summaries?.[0] || null
    };
  } catch (error) {
    console.error('Error fetching lead memory context:', error);
    return null;
  }
}

function buildLeadMemoryPrompt(memory: LeadMemoryContext): string {
  const parts: string[] = [];

  // Nome do lead
  if (memory.lead_name) {
    parts.push(`CLIENTE: ${memory.lead_name} (vocÃª JÃ CONHECE este cliente, NÃƒO pergunte o nome novamente)`);
  }

  // ClassificaÃ§Ã£o
  if (memory.lead_stars) {
    const starsText = memory.lead_stars >= 4 ? 'cliente prioritÃ¡rio' : 
                      memory.lead_stars >= 2 ? 'cliente regular' : 'cliente novo';
    parts.push(`CLASSIFICAÃ‡ÃƒO: ${starsText} (${memory.lead_stars} estrelas)`);
  }

  // PreferÃªncias aprendidas
  if (memory.preferences.length > 0) {
    parts.push('\nğŸ§  O QUE VOCÃŠ JÃ SABE SOBRE ESTE CLIENTE:');
    
    const typeLabels: Record<string, string> = {
      'product_interest': 'Interesses',
      'health_goal': 'Objetivos de saÃºde',
      'concern': 'PreocupaÃ§Ãµes',
      'budget_range': 'OrÃ§amento',
      'communication_style': 'Estilo de comunicaÃ§Ã£o',
      'lifestyle': 'Estilo de vida',
      'timing': 'Timing'
    };

    const grouped: Record<string, string[]> = {};
    for (const pref of memory.preferences) {
      const type = typeLabels[pref.preference_type] || pref.preference_type;
      if (!grouped[type]) grouped[type] = [];
      grouped[type].push(pref.preference_value);
    }

    for (const [type, values] of Object.entries(grouped)) {
      parts.push(`- ${type}: ${values.join('; ')}`);
    }

    parts.push('\nUSE estas informaÃ§Ãµes para personalizar o atendimento. FaÃ§a referÃªncias ao que vocÃª jÃ¡ sabe!');
  }

  // Ãšltima conversa
  if (memory.last_summary) {
    const daysAgo = Math.floor(
      (Date.now() - new Date(memory.last_summary.created_at).getTime()) / (1000 * 60 * 60 * 24)
    );
    
    parts.push(`\nğŸ“ ÃšLTIMA CONVERSA (${daysAgo} dias atrÃ¡s):`);
    parts.push(memory.last_summary.summary_text);
    
    if (memory.last_summary.next_steps) {
      parts.push(`â¡ï¸ PRÃ“XIMO PASSO COMBINADO: ${memory.last_summary.next_steps}`);
    }

    if (memory.last_summary.key_topics.length > 0) {
      parts.push(`TÃ³picos discutidos: ${memory.last_summary.key_topics.join(', ')}`);
    }
  }

  // Notas do vendedor
  if (memory.lead_notes) {
    parts.push(`\nğŸ“‹ NOTAS DO VENDEDOR: ${memory.lead_notes}`);
  }

  return parts.join('\n');
}

// ============================================================================
// AI PROCESSING
// ============================================================================

// ============================================================================
// CONTEXT PROTECTION - Filter problematic messages from history
// ============================================================================

const MAX_MESSAGE_LENGTH = 500; // Maximum chars per message in context
const TECHNICAL_PATTERNS = [
  /^#+\s*[A-Z].*refactor/im,       // Markdown headers with "refactor"
  /^\s*```/m,                       // Code blocks
  /^\s*-{3,}/m,                     // Horizontal rules
  /\b(function|const|let|var|import|export)\s+\w+/i, // Code keywords
  /\.(ts|tsx|js|jsx|py|sql|json):/i, // File references
  /wavoip|webhook|endpoint|api_key|supabase|postgres/i, // Technical terms
  /^\s*\d+\.\s+\*\*[A-Z]/m,        // Numbered technical lists
  /\bPROBLEMA\s*:/i,               // Technical problem descriptions
  /\bSOLUÃ‡ÃƒO\s*:/i,                // Technical solution descriptions
];

function isLikelyTechnicalContent(content: string): boolean {
  // Check for multiple technical indicators
  let technicalScore = 0;
  
  for (const pattern of TECHNICAL_PATTERNS) {
    if (pattern.test(content)) {
      technicalScore++;
    }
  }
  
  // If 2+ patterns match, likely technical
  return technicalScore >= 2;
}

function sanitizeMessageForContext(content: string, direction: 'inbound' | 'outbound'): string | null {
  if (!content || content.length < 2) return null;
  
  // Skip messages that are too long (likely documents/pastes)
  if (content.length > MAX_MESSAGE_LENGTH * 3 && direction === 'inbound') {
    // Check if it's technical content
    if (isLikelyTechnicalContent(content)) {
      console.log('ğŸ›¡ï¸ Filtering technical content from context:', content.substring(0, 100) + '...');
      return null; // Remove entirely from context
    }
    
    // For non-technical long messages, truncate
    return content.substring(0, MAX_MESSAGE_LENGTH) + '... [mensagem longa truncada]';
  }
  
  // For outbound (bot) messages, just truncate if too long
  if (content.length > MAX_MESSAGE_LENGTH && direction === 'outbound') {
    return content.substring(0, MAX_MESSAGE_LENGTH) + '...';
  }
  
  // Regular messages pass through with standard truncation
  if (content.length > MAX_MESSAGE_LENGTH) {
    return content.substring(0, MAX_MESSAGE_LENGTH) + '...';
  }
  
  return content;
}

async function getConversationHistory(conversationId: string, limit = 20): Promise<Array<{role: string, content: string}>> {
  const { data: messages } = await supabase
    .from('whatsapp_messages')
    .select('content, direction, is_from_bot, created_at')
    .eq('conversation_id', conversationId)
    .order('created_at', { ascending: false })
    .limit(limit);

  if (!messages) return [];

  // Inverter para ordem cronolÃ³gica, sanitizar e mapear para formato OpenAI
  return messages.reverse()
    .map(msg => {
      const sanitizedContent = sanitizeMessageForContext(
        msg.content || '', 
        msg.direction as 'inbound' | 'outbound'
      );
      return {
        role: msg.direction === 'inbound' ? 'user' : 'assistant',
        content: sanitizedContent
      };
    })
    .filter((m): m is {role: string, content: string} => !!m.content);
}

function buildBotPersonalityPrompt(bot: AIBot): string {
  const parts: string[] = [];
  
  // Identidade do robÃ´
  if (bot.name) {
    parts.push(`VocÃª Ã© ${bot.name}.`);
  }
  
  // GÃªnero e idade
  if (bot.gender || bot.age_range) {
    const genderText = bot.gender === 'female' ? 'mulher' : bot.gender === 'male' ? 'homem' : 'pessoa';
    const ageText = bot.age_range ? ` de ${bot.age_range.replace('_', ' a ').replace('older', 'mais de')} anos` : '';
    parts.push(`VocÃª Ã© uma ${genderText}${ageText}.`);
  }
  
  // LocalizaÃ§Ã£o e regionalismos
  if (bot.brazilian_state) {
    const stateNames: Record<string, string> = {
      'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'AmapÃ¡', 'AM': 'Amazonas', 'BA': 'Bahia',
      'CE': 'CearÃ¡', 'DF': 'Distrito Federal', 'ES': 'EspÃ­rito Santo', 'GO': 'GoiÃ¡s',
      'MA': 'MaranhÃ£o', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais',
      'PA': 'ParÃ¡', 'PB': 'ParaÃ­ba', 'PR': 'ParanÃ¡', 'PE': 'Pernambuco', 'PI': 'PiauÃ­',
      'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul',
      'RO': 'RondÃ´nia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'SÃ£o Paulo',
      'SE': 'Sergipe', 'TO': 'Tocantins'
    };
    const stateName = stateNames[bot.brazilian_state] || bot.brazilian_state;
    parts.push(`VocÃª Ã© de ${stateName} e usa expressÃµes e sotaque tÃ­picos da regiÃ£o.`);
  }
  
  // ExpressÃµes regionais
  if (bot.regional_expressions && bot.regional_expressions.length > 0) {
    parts.push(`Use naturalmente expressÃµes como: ${bot.regional_expressions.join(', ')}.`);
  }
  
  // Personalidade
  if (bot.personality_description) {
    parts.push(`Sua personalidade: ${bot.personality_description}`);
  }
  
  // Tipo de atendimento
  if (bot.service_type) {
    const serviceTypes: Record<string, string> = {
      'sales': 'VocÃª Ã© especialista em vendas consultivas. Foque em entender a necessidade e oferecer a melhor soluÃ§Ã£o.',
      'support': 'VocÃª foca em suporte e atendimento. Resolva dÃºvidas e problemas com empatia.',
      'scheduling': 'VocÃª Ã© especialista em agendamentos. Ajude a encontrar o melhor horÃ¡rio.',
      'general': 'VocÃª oferece atendimento geral, adaptando-se Ã  necessidade do cliente.'
    };
    parts.push(serviceTypes[bot.service_type] || '');
  }
  
  // Tamanho da resposta
  if (bot.response_length) {
    const lengthGuides: Record<string, string> = {
      'short': 'Seja BREVE e DIRETO. Respostas curtas de 1-2 frases quando possÃ­vel.',
      'medium': 'Use respostas de tamanho mÃ©dio, equilibradas entre brevidade e completude.',
      'long': 'Pode usar respostas mais detalhadas quando necessÃ¡rio explicar algo complexo.'
    };
    parts.push(lengthGuides[bot.response_length] || '');
  }
  
  // Diferencial da empresa
  if (bot.company_differential) {
    parts.push(`DIFERENCIAL DA EMPRESA: ${bot.company_differential}. Mencione isso quando relevante.`);
  }
  
  return parts.join('\n');
}

function buildProductsContext(products: BotProduct[]): string {
  if (!products.length) return '';
  
  const productInfos = products.map(p => {
    let info = `## ${p.name}`;
    
    // Description
    if (p.description) {
      info += `\nğŸ“ DescriÃ§Ã£o: ${p.description}`;
    }
    
    // Kits with prices and sales hacks (prioritize over legacy prices)
    if (p.kits && p.kits.length > 0) {
      const kitPrices = p.kits.map(k => {
        const price = `${k.quantity} un: R$${(k.price_cents / 100).toFixed(2)}`;
        const duration = k.usage_period_days ? ` (${k.usage_period_days} dias)` : '';
        return price + duration;
      }).join(' | ');
      info += `\nğŸ’° PreÃ§os: ${kitPrices}`;
      
      // Sales hacks for kits
      const salesHacks = p.kits
        .filter(k => k.sales_hack)
        .map(k => `Kit ${k.quantity}: ${k.sales_hack}`)
        .join('\n  ');
      if (salesHacks) {
        info += `\nğŸ¯ HACKS DE VENDA:\n  ${salesHacks}`;
      }
    } else {
      // Fallback to legacy prices
      const prices: string[] = [];
      if (p.price_1_unit) prices.push(`1un: R$${(p.price_1_unit / 100).toFixed(2)}`);
      if (p.price_3_units) prices.push(`3un: R$${(p.price_3_units / 100).toFixed(2)}`);
      if (p.price_6_units) prices.push(`6un: R$${(p.price_6_units / 100).toFixed(2)}`);
      if (p.price_12_units) prices.push(`12un: R$${(p.price_12_units / 100).toFixed(2)}`);
      if (prices.length) info += `\nğŸ’° PreÃ§os: ${prices.join(' | ')}`;
    }
    
    // Usage period
    if (p.usage_period_days) {
      info += `\nâ±ï¸ DuraÃ§Ã£o: ${p.usage_period_days} dias de uso`;
    }
    
    // General sales script
    if (p.sales_script) {
      info += `\nğŸ“‹ Script de Vendas: ${p.sales_script}`;
    }
    
    // Ingredients/Composition
    if (p.ingredients && p.ingredients.length > 0) {
      const ingredientList = p.ingredients.map(i => 
        i.description ? `${i.name} (${i.description})` : i.name
      ).join(', ');
      info += `\nğŸ§ª ComposiÃ§Ã£o: ${ingredientList}`;
    }
    
    // FAQs for this product
    if (p.faqs && p.faqs.length > 0) {
      const faqText = p.faqs.slice(0, 5).map(f => 
        `  â€¢ P: ${f.question}\n    R: ${f.answer}`
      ).join('\n');
      info += `\nâ“ Perguntas Frequentes:\n${faqText}`;
    }
    
    // Hot site URL
    if (p.hot_site_url) {
      info += `\nğŸ”— Link: ${p.hot_site_url}`;
    }
    
    return info;
  });
  
  return `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CATÃLOGO DE PRODUTOS (use para responder sobre preÃ§os, benefÃ­cios e caracterÃ­sticas)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

${productInfos.join('\n\n---\n\n')}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DICAS DE VENDAS:
- Sempre mencione que KITS MAIORES tÃªm MELHOR CUSTO-BENEFÃCIO
- Use os HACKS DE VENDA quando disponÃ­veis para cada kit
- Responda dÃºvidas usando as FAQs do produto
- Mencione a composiÃ§Ã£o quando perguntarem sobre ingredientes
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
}

function buildFAQContext(faqs: Array<{question: string, answer: string}>): string {
  if (!faqs.length) return '';
  
  const faqText = faqs.map(f => `P: ${f.question}\nR: ${f.answer}`).join('\n\n');
  
  return `
PERGUNTAS FREQUENTES (use para responder dÃºvidas comuns):
${faqText}`;
}

function buildSemanticContext(results: SemanticSearchResult[]): string {
  if (!results.length) return '';
  
  const grouped: Record<string, string[]> = {};
  
  for (const result of results) {
    const productName = result.metadata?.product_name || 'Produto';
    if (!grouped[productName]) {
      grouped[productName] = [];
    }
    grouped[productName].push(result.content_text);
  }
  
  const sections = Object.entries(grouped).map(([product, contents]) => 
    `ğŸ“Œ ${product}:\n${contents.join('\n\n')}`
  );
  
  return `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INFORMAÃ‡Ã•ES RELEVANTES ENCONTRADAS (via busca semÃ¢ntica):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${sections.join('\n\n---\n\n')}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
}

async function generateAIResponse(
  bot: AIBot, 
  userMessage: string, 
  conversationHistory: Array<{role: string, content: string}>,
  contactName: string,
  messageCount: number = 0,
  products: BotProduct[] = [],
  faqs: Array<{question: string, answer: string}> = [],
  semanticResults: SemanticSearchResult[] = [],
  leadMemory: LeadMemoryContext | null = null,
  modelOverride: string | null = null
): Promise<{ response: string; tokensUsed: number; modelUsed: string }> {
  
  // Determine which model to use (priority: override > bot config > default)
  const modelToUse = modelOverride || bot.ai_model_chat || 'google/gemini-3-flash-preview';
  
  // Construir prompt de personalidade
  const personalityPrompt = buildBotPersonalityPrompt(bot);
  
  // Contexto de produtos
  const productsContext = buildProductsContext(products);
  
  // Contexto de FAQs
  const faqContext = buildFAQContext(faqs);
  
  // Contexto semÃ¢ntico (resultados da busca vetorial)
  const semanticContext = buildSemanticContext(semanticResults);

  // Contexto de memÃ³ria do lead (cross-session)
  const leadMemoryContext = leadMemory ? `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§  MEMÃ“RIA DO CLIENTE (informaÃ§Ãµes aprendidas em conversas anteriores)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${buildLeadMemoryPrompt(leadMemory)}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•` : '';
  
  // Diretrizes de qualificaÃ§Ã£o
  const qualificationInstructions = `
DIRETRIZES DE ATENDIMENTO HUMANIZADO:
1. Seja NATURAL - vocÃª Ã© uma pessoa real, nÃ£o um robÃ´. Converse como se estivesse no WhatsApp.
2. NUNCA transfira nas primeiras mensagens - primeiro entenda o que o cliente precisa.
3. FaÃ§a perguntas para entender melhor. Demonstre interesse genuÃ­no.
4. Se nÃ£o souber algo especÃ­fico, diga que vai verificar.
5. Use emojis com moderaÃ§Ã£o para deixar a conversa mais leve.
6. Personalize: use o nome do cliente, referÃªncias ao que ele disse antes.
${leadMemory ? `7. IMPORTANTE: VocÃª JÃ CONHECE este cliente! Use as informaÃ§Ãµes da MEMÃ“RIA acima para personalizar.
8. NÃƒO pergunte nome, preferÃªncias ou informaÃ§Ãµes que vocÃª jÃ¡ sabe!` : ''}

QUANDO TRANSFERIR:
- Cliente PEDIR explicitamente para falar com pessoa/humano/atendente
- ApÃ³s 5+ trocas sobre o mesmo problema sem resoluÃ§Ã£o
- NegociaÃ§Ã£o de preÃ§o muito especÃ­fica
- ReclamaÃ§Ãµes graves

EVITE:
- Respostas genÃ©ricas tipo "Como posso ajudar?"
- Repetir as mesmas frases
- Ser formal demais - seja amigÃ¡vel!
- Transferir rÃ¡pido demais
${leadMemory ? '- Perguntar informaÃ§Ãµes que vocÃª jÃ¡ sabe sobre o cliente!' : ''}`;

  // System prompt completo e rico
  const systemPrompt = `${personalityPrompt}

${bot.system_prompt || 'VocÃª Ã© um assistente de atendimento prestativo e empÃ¡tico.'}

CONTEXTO ATUAL:
- Cliente: ${leadMemory?.lead_name || contactName}
- Data/Hora: ${new Date().toLocaleString('pt-BR', { timeZone: 'America/Sao_Paulo' })}
- Mensagens na conversa: ${messageCount}

${leadMemoryContext}

${semanticContext}

${productsContext}

${faqContext}

${qualificationInstructions}

LEMBRE-SE: VocÃª Ã© um HUMANO conversando pelo WhatsApp. Seja natural, empÃ¡tico e Ãºtil.
${leadMemory ? 'PRIORIZE usar as informaÃ§Ãµes da MEMÃ“RIA DO CLIENTE para personalizar o atendimento!' : ''}
${semanticResults.length > 0 ? 'Use as informaÃ§Ãµes da busca semÃ¢ntica para responder perguntas tÃ©cnicas.' : ''}`;

  const messages = [
    { role: 'system', content: systemPrompt },
    ...conversationHistory.slice(-15),
    { role: 'user', content: userMessage }
  ];

  console.log('ğŸ¤– Calling AI model:', modelToUse, 'with enriched context:', {
    hasProducts: products.length > 0,
    hasFAQs: faqs.length > 0,
    hasSemanticResults: semanticResults.length > 0,
    personality: !!personalityPrompt,
    messagesCount: messages.length
  });

  const response = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${LOVABLE_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: modelToUse,
      messages,
      max_tokens: 600,
      temperature: 0.85, // Mais natural e variado
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error('âŒ Lovable AI error:', response.status, errorText);
    
    if (response.status === 429) {
      throw new Error('RATE_LIMITED');
    }
    if (response.status === 402) {
      throw new Error('PAYMENT_REQUIRED');
    }
    throw new Error(`AI_ERROR: ${response.status}`);
  }

  const data = await response.json();
  const aiResponse = data.choices?.[0]?.message?.content || '';
  const tokensUsed = (data.usage?.prompt_tokens || 0) + (data.usage?.completion_tokens || 0);

  console.log('âœ… AI Response generated with', modelToUse, ':', aiResponse.substring(0, 100) + '...');
  
  return { response: aiResponse, tokensUsed, modelUsed: modelToUse };
}

// ============================================================================
// SEND MESSAGE VIA EVOLUTION
// ============================================================================

async function sendWhatsAppMessage(
  instanceName: string, 
  chatId: string, 
  message: string,
  conversationId: string,
  instanceId: string,
  botId: string
): Promise<boolean> {
  try {
    const endpoint = `${EVOLUTION_API_URL}/message/sendText/${instanceName}`;
    
    console.log('ğŸ“¤ Sending message via Evolution:', {
      instance: instanceName,
      chatId,
      messagePreview: message.substring(0, 50) + '...'
    });

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'apikey': EVOLUTION_API_KEY,
      },
      body: JSON.stringify({
        number: chatId,
        text: message,
      }),
    });

    if (!response.ok) {
      console.error('âŒ Evolution send failed:', response.status);
      return false;
    }

    const result = await response.json();
    const providerMessageId = result?.key?.id || null;

    // Salvar mensagem no banco
    await supabase.from('whatsapp_messages').insert({
      id: crypto.randomUUID(),
      instance_id: instanceId,
      conversation_id: conversationId,
      message_type: 'text',
      content: message,
      direction: 'outbound',
      status: 'sent',
      is_from_bot: true,
      provider: 'evolution',
      provider_message_id: providerMessageId,
    });

    console.log('âœ… Bot message sent and saved');
    return true;
  } catch (error) {
    console.error('âŒ Error sending message:', error);
    return false;
  }
}

// Send audio message via Evolution API
async function sendWhatsAppAudio(
  instanceName: string,
  chatId: string,
  audioUrl: string,
  conversationId: string,
  instanceId: string,
  botId: string
): Promise<boolean> {
  try {
    const endpoint = `${EVOLUTION_API_URL}/message/sendWhatsAppAudio/${instanceName}`;
    
    console.log('ğŸ¤ Sending audio message:', { instanceName, chatId, audioUrl: audioUrl.substring(0, 50) + '...' });

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'apikey': EVOLUTION_API_KEY,
      },
      body: JSON.stringify({
        number: chatId,
        audio: audioUrl,
      }),
    });

    if (!response.ok) {
      console.error('âŒ Evolution audio send failed:', response.status);
      return false;
    }

    const result = await response.json();
    const providerMessageId = result?.key?.id || null;

    // Salvar mensagem no banco
    await supabase.from('whatsapp_messages').insert({
      id: crypto.randomUUID(),
      instance_id: instanceId,
      conversation_id: conversationId,
      message_type: 'audio',
      media_url: audioUrl,
      direction: 'outbound',
      status: 'sent',
      is_from_bot: true,
      provider: 'evolution',
      provider_message_id: providerMessageId,
    });

    console.log('âœ… Bot audio message sent and saved');
    return true;
  } catch (error) {
    console.error('âŒ Error sending audio:', error);
    return false;
  }
}

// ============================================================================
// ENERGY MANAGEMENT
// ============================================================================

async function checkAndConsumeEnergy(
  organizationId: string, 
  botId: string,
  conversationId: string,
  tokensUsed: number,
  actionType: string,
  modelUsed: string = 'google/gemini-2.5-flash',
  realCostUsd: number | null = null
): Promise<{ success: boolean; energyConsumed: number }> {
  // Calcular energia baseada em tokens (1 energia = ~100 tokens para modelo padrÃ£o)
  // Para modelos mais caros, ajustar proporcionalmente
  let energyMultiplier = 1;
  if (modelUsed.includes('gemini-2.5-pro') || modelUsed.includes('gemini-3-pro')) {
    energyMultiplier = 3; // Modelos pro custam 3x mais
  } else if (modelUsed.includes('gpt-5.2') || modelUsed.includes('gpt-5')) {
    energyMultiplier = 5; // GPT-5 custa 5x mais
  }
  
  const baseEnergy = Math.max(1, Math.ceil(tokensUsed / 100));
  const energyToConsume = Math.max(1, Math.ceil(baseEnergy * energyMultiplier));

  // Estimar custo real se nÃ£o foi passado (baseado em custos mÃ©dios)
  const estimatedCost = realCostUsd ?? (tokensUsed / 1000000 * 0.5); // ~$0.50 por 1M tokens mÃ©dio

  // Consumir energia via RPC (tambÃ©m registra metadados/uso no backend)
  const { data, error } = await supabase.rpc('consume_energy', {
    p_organization_id: organizationId,
    p_bot_id: botId,
    p_conversation_id: conversationId,
    p_action_type: actionType,
    p_energy_amount: energyToConsume,
    p_tokens_used: tokensUsed,
    p_details: { timestamp: new Date().toISOString() },
    p_model_used: modelUsed,
    p_real_cost_usd: estimatedCost,
  });

  if (error) {
    console.error('âš¡ consume_energy error:', error);
    return { success: false, energyConsumed: 0 };
  }

  // A funÃ§Ã£o pode retornar boolean ou JSON (dependendo da implementaÃ§Ã£o)
  const ok = typeof data === 'boolean' ? data : (data?.success ?? true);

  if (!ok) {
    console.log('âš¡ No energy available');
    return { success: false, energyConsumed: 0 };
  }

  console.log('âš¡ Energy consumed:', energyToConsume, 'model:', modelUsed);
  return { success: true, energyConsumed: energyToConsume };
}

// ============================================================================
// TRANSFER TO HUMAN
// ============================================================================

async function transferToHuman(
  conversationId: string,
  reason: string,
  transferMessage: string | null
): Promise<void> {
  console.log('ğŸ”„ Transferring to human:', reason);

  // Usar a funÃ§Ã£o do banco para transferir
  await supabase.rpc('transfer_from_bot_to_human', {
    p_conversation_id: conversationId
  });

  // Se tem mensagem de transferÃªncia, ela jÃ¡ foi enviada ou serÃ¡ enviada
  console.log('âœ… Transferred to human, status now pending');
}

// ============================================================================
// QUALIFICATION LOGIC
// ============================================================================

async function processQualification(
  bot: AIBot,
  context: ConversationContext,
  userMessage: string,
  instanceName: string
): Promise<{ shouldContinue: boolean; result?: ProcessResult }> {
  
  // Se qualificaÃ§Ã£o nÃ£o estÃ¡ habilitada ou jÃ¡ foi completada, continuar normal
  if (!bot.initial_qualification_enabled || !bot.initial_questions || bot.initial_questions.length === 0) {
    return { shouldContinue: true };
  }

  if (context.qualificationCompleted) {
    return { shouldContinue: true };
  }

  const questions = bot.initial_questions;
  const currentStep = context.qualificationStep;

  console.log('ğŸ“‹ Qualification step:', currentStep, 'of', questions.length);

  // Se Ã© o primeiro passo (step = 0), enviar primeira pergunta
  if (currentStep === 0) {
    const firstQuestion = questions[0];
    const questionMessage = formatQualificationQuestion(firstQuestion, 1, questions.length);
    
    await sendWhatsAppMessage(
      instanceName,
      context.chatId,
      questionMessage,
      context.conversationId,
      context.instanceId,
      bot.id
    );

    // Atualizar step para 1 (esperando resposta da primeira pergunta)
    await supabase
      .from('whatsapp_conversations')
      .update({ bot_qualification_step: 1 })
      .eq('id', context.conversationId);

    // Consumir energia
    await checkAndConsumeEnergy(context.organizationId, bot.id, context.conversationId, 30, 'qualification_question');

    return { 
      shouldContinue: false, 
      result: { success: true, action: 'qualification', message: 'First question sent' } 
    };
  }

  // Salvar resposta da pergunta anterior
  const previousQuestion = questions[currentStep - 1];
  if (context.leadId) {
    await saveQualificationAnswer(
      context.leadId,
      context.organizationId,
      previousQuestion,
      userMessage
    );
    console.log('âœ… Saved answer for question:', previousQuestion.questionText);
  }

  // Verificar se hÃ¡ mais perguntas
  if (currentStep < questions.length) {
    const nextQuestion = questions[currentStep];
    const questionMessage = formatQualificationQuestion(nextQuestion, currentStep + 1, questions.length);
    
    await sendWhatsAppMessage(
      instanceName,
      context.chatId,
      questionMessage,
      context.conversationId,
      context.instanceId,
      bot.id
    );

    // Atualizar step
    await supabase
      .from('whatsapp_conversations')
      .update({ bot_qualification_step: currentStep + 1 })
      .eq('id', context.conversationId);

    // Consumir energia
    await checkAndConsumeEnergy(context.organizationId, bot.id, context.conversationId, 30, 'qualification_question');

    return { 
      shouldContinue: false, 
      result: { success: true, action: 'qualification', message: `Question ${currentStep + 1} sent` } 
    };
  }

  // Todas as perguntas foram respondidas
  await supabase
    .from('whatsapp_conversations')
    .update({ bot_qualification_completed: true })
    .eq('id', context.conversationId);

  console.log('âœ… Qualification completed');

  // Enviar mensagem de transiÃ§Ã£o
  const transitionMessage = `Obrigado pelas informaÃ§Ãµes, ${context.contactName}! ğŸ™ Agora posso te ajudar melhor. Como posso te atender?`;
  
  await sendWhatsAppMessage(
    instanceName,
    context.chatId,
    transitionMessage,
    context.conversationId,
    context.instanceId,
    bot.id
  );

  await checkAndConsumeEnergy(context.organizationId, bot.id, context.conversationId, 30, 'qualification_complete');

  return { shouldContinue: true };
}

function formatQualificationQuestion(question: InitialQuestion, number: number, total: number): string {
  const prefix = `ğŸ“‹ *Pergunta ${number}/${total}*\n\n`;
  return prefix + question.questionText;
}

async function saveQualificationAnswer(
  leadId: string,
  organizationId: string,
  question: InitialQuestion,
  answer: string
): Promise<void> {
  try {
    // Preparar dados baseado no tipo de pergunta
    const answerData: any = {
      lead_id: leadId,
      question_id: question.questionId,
      organization_id: organizationId,
      updated_at: new Date().toISOString(),
    };

    switch (question.questionType) {
      case 'number':
        // Tentar extrair nÃºmero da resposta
        const numMatch = answer.match(/\d+([.,]\d+)?/);
        if (numMatch) {
          answerData.numeric_value = parseFloat(numMatch[0].replace(',', '.'));
        }
        break;
      
      case 'text':
        answerData.text_value = answer;
        break;

      case 'imc_calculator':
        // Tentar extrair peso, altura e idade da resposta
        // Formato esperado: "75kg 1.70m 30 anos" ou similar
        const weightMatch = answer.match(/(\d+([.,]\d+)?)\s*(kg|quilo)/i);
        const heightMatch = answer.match(/(\d+([.,]\d+)?)\s*(m|metro|cm)/i);
        const ageMatch = answer.match(/(\d+)\s*(anos?|age)/i);
        
        if (weightMatch) {
          answerData.imc_weight = parseFloat(weightMatch[1].replace(',', '.'));
        }
        if (heightMatch) {
          let height = parseFloat(heightMatch[1].replace(',', '.'));
          // Se altura > 3, provavelmente estÃ¡ em cm
          if (height > 3) height = height / 100;
          answerData.imc_height = height;
        }
        if (ageMatch) {
          answerData.imc_age = parseInt(ageMatch[1]);
        }
        
        // Calcular IMC se tiver peso e altura
        if (answerData.imc_weight && answerData.imc_height) {
          const imc = answerData.imc_weight / (answerData.imc_height * answerData.imc_height);
          answerData.imc_result = Math.round(imc * 100) / 100;
          
          // Categorizar
          if (imc < 18.5) answerData.imc_category = 'Abaixo do peso';
          else if (imc < 25) answerData.imc_category = 'Peso normal';
          else if (imc < 30) answerData.imc_category = 'Sobrepeso';
          else if (imc < 35) answerData.imc_category = 'Obesidade grau I';
          else if (imc < 40) answerData.imc_category = 'Obesidade grau II';
          else answerData.imc_category = 'Obesidade grau III';
        }
        break;
      
      case 'single_choice':
      case 'multiple_choice':
        // Para escolhas, salvar o texto como referÃªncia
        // Idealmente, buscarÃ­amos as opÃ§Ãµes e matchearÃ­amos
        answerData.text_value = answer;
        break;
      
      default:
        answerData.text_value = answer;
    }

    // Upsert a resposta
    const { error } = await supabase
      .from('lead_standard_question_answers')
      .upsert(answerData, {
        onConflict: 'lead_id,question_id',
        ignoreDuplicates: false
      });

    if (error) {
      console.error('âŒ Error saving qualification answer:', error);
    }
  } catch (err) {
    console.error('âŒ Error in saveQualificationAnswer:', err);
  }
}

// ============================================================================
// MAIN PROCESS
// ============================================================================

async function processMessage(
  bot: AIBot,
  context: ConversationContext,
  userMessage: string,
  instanceName: string,
  isWithinSchedule: boolean = true // Novo parÃ¢metro - vem do webhook
): Promise<ProcessResult> {
  
  console.log('ğŸ¤– Processing message for bot:', bot.name);
  
  // 0. Processar qualificaÃ§Ã£o inicial (se habilitada)
  const qualificationResult = await processQualification(bot, context, userMessage, instanceName);
  if (!qualificationResult.shouldContinue && qualificationResult.result) {
    return qualificationResult.result;
  }

  // 1. Verificar horÃ¡rio de funcionamento (usando isWithinSchedule do webhook)
  // Se estÃ¡ fora do horÃ¡rio agendado, enviar mensagem de fora de horÃ¡rio mas CONTINUAR INTERAGINDO
  if (!isWithinSchedule) {
    console.log('â° Outside scheduled hours - will still respond with out-of-hours context');
    
    // Se Ã© primeira mensagem fora do horÃ¡rio, enviar aviso
    // Depois continua processando normalmente para poder interagir
    if (context.botMessagesCount === 0 && bot.out_of_hours_message) {
      await sendWhatsAppMessage(
        instanceName,
        context.chatId,
        bot.out_of_hours_message,
        context.conversationId,
        context.instanceId,
        bot.id
      );
      
      // Consumir energia pelo aviso de fora de horÃ¡rio
      await checkAndConsumeEnergy(
        context.organizationId,
        bot.id,
        context.conversationId,
        30,
        'out_of_hours_message'
      );
      
      // Incrementar contador para nÃ£o enviar novamente
      await supabase
        .from('whatsapp_conversations')
        .update({ bot_messages_count: 1 })
        .eq('id', context.conversationId);
      
      context.botMessagesCount = 1;
    }
    // Continua processando - o robÃ´ vai responder normalmente
  }

  // 2. Verificar keywords de transferÃªncia
  if (shouldTransferByKeywords(userMessage, bot.transfer_keywords)) {
    console.log('ğŸ”‘ Transfer keyword detected');
    
    await transferToHuman(context.conversationId, 'keyword_trigger', bot.transfer_message);
    
    if (bot.transfer_message) {
      await sendWhatsAppMessage(
        instanceName,
        context.chatId,
        bot.transfer_message,
        context.conversationId,
        context.instanceId,
        bot.id
      );
    }
    
    return { success: true, action: 'transferred', message: 'Transfer keyword detected' };
  }

  // 3. Verificar limite de mensagens - aumentado para dar mais tempo ao robÃ´ qualificar
  // MÃ­nimo de 5 mensagens antes de transferir por limite
  const effectiveMaxMessages = bot.max_messages_before_transfer 
    ? Math.max(bot.max_messages_before_transfer, 5) 
    : 15; // Se nÃ£o configurado, usar 15 como padrÃ£o
    
  if (context.botMessagesCount >= effectiveMaxMessages) {
    console.log('ğŸ“Š Max messages reached, transferring');
    
    await transferToHuman(context.conversationId, 'max_messages', bot.transfer_message);
    
    if (bot.transfer_message) {
      await sendWhatsAppMessage(
        instanceName,
        context.chatId,
        bot.transfer_message,
        context.conversationId,
        context.instanceId,
        bot.id
      );
    }
    
    return { success: true, action: 'transferred', message: 'Max messages reached' };
  }

  // 4. Buscar histÃ³rico da conversa
  const conversationHistory = await getConversationHistory(context.conversationId);

  // 5. Buscar produtos e conhecimento do bot para contexto enriquecido
  const productScope = (bot as any).product_scope || 'all';
  const useRagSearch = (bot as any).use_rag_search ?? false;
  
  // 5.1 Buscar configuraÃ§Ãµes globais de IA da organizaÃ§Ã£o
  const { data: orgAISettings } = await supabase
    .from('organizations')
    .select('whatsapp_ai_memory_enabled, whatsapp_ai_learning_enabled')
    .eq('id', context.organizationId)
    .single();
  
  const aiMemoryEnabled = (orgAISettings as any)?.whatsapp_ai_memory_enabled ?? false;
  const aiLearningEnabled = (orgAISettings as any)?.whatsapp_ai_learning_enabled ?? false;
  
  // 5.2 Buscar contexto de memÃ³ria do lead (cross-session learning) - SOMENTE se habilitado
  let leadMemory: LeadMemoryContext | null = null;
  if (context.leadId && aiMemoryEnabled) {
    leadMemory = await getLeadMemoryContext(context.organizationId, context.leadId);
    if (leadMemory) {
      console.log('ğŸ§  Lead memory loaded (memory enabled):', {
        hasPreferences: leadMemory.preferences.length > 0,
        hasLastSummary: !!leadMemory.last_summary,
        leadName: leadMemory.lead_name
      });
    }
  } else if (context.leadId && !aiMemoryEnabled) {
    console.log('ğŸ§  Lead memory disabled globally, skipping');
  }
  
  const [products, faqs] = await Promise.all([
    getBotProducts(bot.id, context.organizationId, productScope),
    getBotKnowledge(bot.id)
  ]);
  
  // 5.2 Busca semÃ¢ntica (RAG) se habilitada
  let semanticResults: SemanticSearchResult[] = [];
  if (useRagSearch && productScope !== 'none') {
    // Get product IDs for filtering (if using selected scope)
    let productIds: string[] | null = null;
    if (productScope === 'selected' && products.length > 0) {
      productIds = products.map(p => p.id);
    }
    
    // Perform semantic search with user's message
    semanticResults = await semanticSearch(
      userMessage, 
      context.organizationId, 
      productIds,
      5 // Top 5 results
    );
  }
  
  console.log('ğŸ“¦ Bot context loaded:', { 
    products: products.length, 
    faqs: faqs.length,
    semanticResults: semanticResults.length,
    ragEnabled: useRagSearch,
    hasLeadMemory: !!leadMemory
  });

  // 6. Gerar resposta IA com contexto completo
  let aiResponse: string;
  let tokensUsed: number;
  let modelUsed: string = bot.ai_model_chat || 'google/gemini-3-flash-preview';
  
  try {
    const result = await generateAIResponse(
      bot, 
      userMessage, 
      conversationHistory, 
      context.contactName, 
      context.botMessagesCount,
      products,
      faqs,
      semanticResults,
      leadMemory
    );
    aiResponse = result.response;
    tokensUsed = result.tokensUsed;
    modelUsed = result.modelUsed;
  } catch (error: any) {
    console.error('âŒ AI generation error:', error.message);
    
    if (error.message === 'RATE_LIMITED' || error.message === 'PAYMENT_REQUIRED') {
      // Transferir para humano se sem crÃ©ditos
      await transferToHuman(context.conversationId, 'no_credits', bot.transfer_message);
      return { success: false, action: 'no_energy', message: error.message };
    }
    
    return { success: false, action: 'error', message: error.message };
  }

  // 6. Consumir energia - using the model that was actually used
  const energyResult = await checkAndConsumeEnergy(
    context.organizationId,
    bot.id,
    context.conversationId,
    tokensUsed,
    'ai_response',
    modelUsed
  );

  if (!energyResult.success) {
    // Sem energia, transferir para humano
    await transferToHuman(context.conversationId, 'no_energy', bot.transfer_message);
    
    if (bot.transfer_message) {
      // Tentar enviar mensagem de transferÃªncia mesmo sem energia
      await sendWhatsAppMessage(
        instanceName,
        context.chatId,
        bot.transfer_message,
        context.conversationId,
        context.instanceId,
        bot.id
      );
    }
    
    return { success: true, action: 'no_energy', message: 'No energy available' };
  }

  // 7. Decidir se responde com Ã¡udio ou texto
  let sent = false;
  let voiceEnergyConsumed = 0;
  
  const shouldSendAudio = bot.voice_enabled && 
    bot.audio_response_probability && 
    Math.random() * 100 < bot.audio_response_probability;
  
  if (shouldSendAudio && bot.voice_id) {
    console.log('ğŸ¤ Generating voice response...');
    
    try {
      // Call TTS edge function
      const ttsResponse = await fetch(`${SUPABASE_URL}/functions/v1/elevenlabs-tts`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${SUPABASE_SERVICE_ROLE_KEY}`,
        },
        body: JSON.stringify({
          text: aiResponse,
          voiceId: bot.voice_id,
          organizationId: context.organizationId,
          botId: bot.id,
          conversationId: context.conversationId,
          voiceStyle: bot.voice_style || 'natural',
        }),
      });
      
      if (ttsResponse.ok) {
        const ttsData = await ttsResponse.json();
        
        if (ttsData.success && ttsData.audioUrl) {
          // Send audio message via Evolution API
          sent = await sendWhatsAppAudio(
            instanceName,
            context.chatId,
            ttsData.audioUrl,
            context.conversationId,
            context.instanceId,
            bot.id
          );
          
          voiceEnergyConsumed = ttsData.energyConsumed || 0;
          console.log('âœ… Voice message sent, energy:', voiceEnergyConsumed);
        }
      }
      
      if (!sent) {
        console.log('âš ï¸ Voice failed, falling back to text');
      }
    } catch (error) {
      console.error('âŒ Voice generation error:', error);
    }
  }
  
  // Fallback to text if voice failed or not enabled
  if (!sent) {
    sent = await sendWhatsAppMessage(
      instanceName,
      context.chatId,
      aiResponse,
      context.conversationId,
      context.instanceId,
      bot.id
    );
  }

  if (!sent) {
    return { success: false, action: 'error', message: 'Failed to send message' };
  }

  // 8. Atualizar contadores da conversa
  const totalEnergy = energyResult.energyConsumed + voiceEnergyConsumed;
  await supabase
    .from('whatsapp_conversations')
    .update({
      bot_messages_count: context.botMessagesCount + 1,
      bot_energy_consumed: context.botEnergyConsumed + totalEnergy,
    })
    .eq('id', context.conversationId);

  return { 
    success: true, 
    action: 'responded', 
    energyUsed: totalEnergy 
  };
}

// ============================================================================
// HANDLER
// ============================================================================

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const body = await req.json();
    
    const {
      botId,
      conversationId,
      instanceId,
      instanceName,
      organizationId,
      userMessage,
      contactName,
      phoneNumber,
      chatId,
      isFirstMessage,
      messageType = 'text',
      mediaUrl,
      mediaMimeType,
      isWithinSchedule = true, // Novo campo do webhook - indica se estÃ¡ dentro do horÃ¡rio agendado
    } = body;

    console.log('ğŸ¤– AI Bot Process request:', {
      botId,
      conversationId,
      isFirstMessage,
      messageType,
      hasMedia: !!mediaUrl,
      isWithinSchedule,
      messagePreview: userMessage?.substring(0, 50)
    });

    // Validar inputs
    if (!botId || !conversationId) {
      return new Response(JSON.stringify({ 
        error: 'Missing required fields',
        success: false 
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Buscar bot
    const { data: bot, error: botError } = await supabase
      .from('ai_bots')
      .select('*')
      .eq('id', botId)
      .eq('is_active', true)
      .single();

    if (botError || !bot) {
      console.error('âŒ Bot not found or inactive:', botId);
      return new Response(JSON.stringify({ 
        error: 'Bot not found or inactive',
        success: false 
      }), {
        status: 404,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Buscar dados da conversa
    const { data: conversation } = await supabase
      .from('whatsapp_conversations')
      .select('bot_messages_count, bot_energy_consumed, lead_id, bot_qualification_step, bot_qualification_completed')
      .eq('id', conversationId)
      .single();

    const context: ConversationContext = {
      conversationId,
      instanceId,
      organizationId,
      contactName: contactName || 'Cliente',
      phoneNumber,
      chatId,
      botMessagesCount: conversation?.bot_messages_count || 0,
      botEnergyConsumed: conversation?.bot_energy_consumed || 0,
      leadId: conversation?.lead_id || null,
      qualificationStep: conversation?.bot_qualification_step || 0,
      qualificationCompleted: conversation?.bot_qualification_completed || false,
    };

    // Se Ã© primeira mensagem e tem welcome message, enviar primeiro
    if (isFirstMessage && bot.welcome_message) {
      console.log('ğŸ‘‹ Sending welcome message');
      await sendWhatsAppMessage(
        instanceName,
        chatId,
        bot.welcome_message,
        conversationId,
        instanceId,
        bot.id
      );
      
      // Consumir energia pelo welcome
      await checkAndConsumeEnergy(organizationId, bot.id, conversationId, 50, 'welcome_message');
    }

    // Processar mensagem baseado no tipo
    let processedMessage = userMessage || '';
    let mediaProcessingEnergy = 0;

    // TRANSCRIÃ‡ÃƒO DE ÃUDIO
    if (messageType === 'audio' && mediaUrl) {
      console.log('ğŸ¤ Processing audio message...');
      
      try {
        const transcription = await transcribeAudio(mediaUrl);
        processedMessage = `[Ãudio transcrito]: ${transcription.text}`;
        
        // Consumir energia pela transcriÃ§Ã£o
        const audioEnergy = await checkAndConsumeEnergy(
          organizationId, 
          botId, 
          conversationId, 
          transcription.tokensUsed, 
          'audio_transcription',
          'openai/whisper'
        );
        
        if (!audioEnergy.success) {
          console.log('âš¡ No energy for audio transcription');
          return new Response(JSON.stringify({ 
            success: false, 
            action: 'no_energy', 
            message: 'No energy for audio transcription' 
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          });
        }
        
        mediaProcessingEnergy += audioEnergy.energyConsumed;
        console.log('âœ… Audio transcribed and energy consumed:', audioEnergy.energyConsumed);
      } catch (audioError) {
        console.error('âŒ Audio transcription failed:', audioError);
        processedMessage = '[Ãudio nÃ£o pÃ´de ser transcrito. Por favor, digite sua mensagem.]';
      }
    }

    // ANÃLISE DE IMAGEM
    if (messageType === 'image' && mediaUrl) {
      console.log('ğŸ–¼ï¸ Processing image message...');
      
      try {
        // Buscar configuraÃ§Ãµes da organizaÃ§Ã£o para modo mÃ©dico de imagens
        const { data: orgSettings } = await supabase
          .from('organizations')
          .select('whatsapp_image_interpretation, whatsapp_image_medical_mode, ai_model_image')
          .eq('id', organizationId)
          .single();

        const useImageMedicalMode = orgSettings?.whatsapp_image_medical_mode ?? false;
        const imageInterpretationEnabled = orgSettings?.whatsapp_image_interpretation ?? false;
        const imageModel = (orgSettings as any)?.ai_model_image || 'google/gemini-2.5-flash';

        // Se a interpretaÃ§Ã£o de imagem nÃ£o estÃ¡ habilitada globalmente, pular
        if (!imageInterpretationEnabled) {
          console.log('ğŸ“· Image interpretation disabled globally, skipping analysis');
          processedMessage = userMessage || '[O cliente enviou uma imagem]';
        } else {
          console.log('ğŸ“· Image interpretation enabled, medical mode:', useImageMedicalMode, 'model:', imageModel);
          
          const imageAnalysis = await analyzeImage(mediaUrl, userMessage, bot.system_prompt, useImageMedicalMode, imageModel);
          
          // Para imagens, a resposta da anÃ¡lise jÃ¡ Ã© a resposta do bot
          // Consumir energia pela anÃ¡lise
          const imageEnergy = await checkAndConsumeEnergy(
            organizationId, 
            botId, 
            conversationId, 
            imageAnalysis.tokensUsed, 
            useImageMedicalMode ? 'image_medical_turbo' : 'image_analysis',
            imageAnalysis.modelUsed
          );
          
          if (!imageEnergy.success) {
            console.log('âš¡ No energy for image analysis');
            return new Response(JSON.stringify({ 
              success: false, 
              action: 'no_energy', 
              message: 'No energy for image analysis' 
            }), {
              headers: { ...corsHeaders, 'Content-Type': 'application/json' },
            });
          }

          // Enviar a resposta da anÃ¡lise de imagem diretamente
          const sent = await sendWhatsAppMessage(
            instanceName,
            chatId,
            imageAnalysis.text,
            conversationId,
            instanceId,
            botId
          );

          // Atualizar contadores
          await supabase
            .from('whatsapp_conversations')
            .update({
              bot_messages_count: context.botMessagesCount + 1,
              bot_energy_consumed: context.botEnergyConsumed + imageEnergy.energyConsumed,
            })
            .eq('id', conversationId);

          return new Response(JSON.stringify({ 
            success: sent, 
            action: 'responded', 
            energyUsed: imageEnergy.energyConsumed,
            messageType: 'image_analysis'
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          });
        }
      } catch (imageError) {
        console.error('âŒ Image analysis failed:', imageError);
        processedMessage = userMessage || 'O cliente enviou uma imagem que nÃ£o pÃ´de ser analisada.';
      }
    }

    // Se nÃ£o tem mensagem para processar (ex: imagem sem texto apÃ³s falha)
    if (!processedMessage) {
      return new Response(JSON.stringify({ 
        success: false, 
        action: 'error', 
        message: 'No message to process' 
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Processar mensagem (texto ou Ã¡udio transcrito)
    const result = await processMessage(bot, context, processedMessage, instanceName, isWithinSchedule);

    // Adicionar energia de processamento de mÃ­dia ao resultado
    if (mediaProcessingEnergy > 0 && result.energyUsed) {
      result.energyUsed += mediaProcessingEnergy;
    }

    return new Response(JSON.stringify(result), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error: any) {
    console.error('âŒ AI Bot Process error:', error);
    return new Response(JSON.stringify({ 
      error: error.message,
      success: false,
      action: 'error'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});
